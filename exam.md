# Билеты

1. Алгоритм обратного распространения ошибки (Backpropagation)  
2. Методы регуляризации нейронных сетей.  
3. Автоматическое дифференцирование и вычислительные графы.  
4. Оптимизационные алгоритмы обучения нейронных сетей.
5. Сверточные нейронные сети: классические архитектуры и transfer learning.  
6. Компьютерное зрение: детекция объектов, семантическая сегментация и регуляризация сверточных слоев.  
7. Представления слов: дистрибутивная гипотеза и модели Word2Vec. Способы токенизации.  
8. Рекуррентные нейронные сети и их разновидности.  
9. Архитектуры Transformer: BERT, GPT и seq2seq-модели.  
10. Обработка аудиосигналов: вейвформы, спектрограммы, ASR-модели (CTC, LAS, RNN-T) и аудио-аугментации.  
11. Генеративное моделирование: GAN и их варианты (WGAN и др.).  
12. Неявные 3D-представления: нейронные поля и NeRF.  
13. Vision Transformers и мультимодальные LLM: CLIP, LLaVA и родственные подходы.  

# Теоретический минимум

1. В чём состоит идея алгоритма обратного распространения ошибки? Приведите формулы.    
2. Почему градиенты в глубоких сетях могут взрываться или затухать при backpropagation? Какие вы знаете способы чтобы это исправить? Что такое gradient clipping?  
3. Что такое dropout, как он влияет на обучение сети?    
4. Объясните механизм batch normalization. Как он влияет на сходимость оптимизации.   
5. Inductive bias. Примеры.  
6. Какие есть недостатки batchnorm. Какие вы знаете альтернативы его использованию?   
7. Как устроен autograd в библиотеке PyTorch?    
8. В чём плюсы/минусы адаптивных оптимизаторов и когда целесообразно делать fine-tuning на SGD (AdamW \-\> SGD).  
9. Архитектура ResNet. Как shortcut-соединения влияют на градиенты?    
10. Что такое transfer learning в CNN: какие слои принято «замораживать» и почему?  Full-fine-tuning vs LoRA.  
11. Опишите различия между задачами object detection и semantic segmentation. Основные метрики.    
12. Зачем применяют dilated (atrous) convolution и в каких задачах это особенно полезно?    
13. Чем GloVe отличается от Word2Vec?    
14. LSTM, RNN vs Seq2Seq+Attention.  
15. GRU vs LSTM.   
16. Что такое self-attention? Какая связь с рекуррентностью в Transformer?  
17. KV-cache: основная идея, зачем используют?  
18. Как работает позиционное кодирование в архитектуре Transformer и какие есть его разновидности?    
19. Pre-training / fine-tuning BERT.  
20. Что такое лог-мел спектрограмма. Почему она используется вместо вейвформы в ASR?    
21. Какие виды аудио-аугментаций вы знаете?    
22. Объясните принцип обучения GAN. Опишите проблему mode collapse.    
23. Как Wasserstein-GAN решает проблемы классического GAN? Что такое gradient penalty?    
24. Что такое NeRF? Какую задачу он решает?   
25. В чём архитектурные преимущества ViT и как они проявляются при работе с high-res изображениями?   
26. Какие трюки позволяют снизить квадратичную сложность self-attention?  
27. Как работает контрастивное обучение в CLIP? В чем мультимодальность?    
28. GNN. Какие задачи решают GNN?
