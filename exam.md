# Билеты

1. Алгоритм обратного распространения ошибки (Backpropagation)  
2. Методы регуляризации нейронных сетей.  
3. Автоматическое дифференцирование и вычислительные графы.  
4. Оптимизационные алгоритмы обучения нейронных сетей.
5. Сверточные нейронные сети: классические архитектуры и transfer learning.  
6. Компьютерное зрение: детекция объектов, семантическая сегментация и регуляризация сверточных слоев.  
7. Представления слов: дистрибутивная гипотеза и модели Word2Vec. Способы токенизации.  
8. Рекуррентные нейронные сети и их разновидности.  
9. Архитектуры Transformer: BERT, GPT и seq2seq-модели.  
10. Обработка аудиосигналов: вейвформы, спектрограммы, ASR-модели (CTC, LAS, RNN-T) и аудио-аугментации.  
11. Генеративное моделирование: GAN и их варианты (WGAN и др.).  
12. Неявные 3D-представления: нейронные поля и NeRF.  
13. Vision Transformers и мультимодальные LLM: CLIP, LLaVA и родственные подходы.  

# Теоретический минимум

1. В чём состоит идея алгоритма обратного распространения ошибки? Приведите формулы.    
2. Почему градиенты в глубоких сетях могут взрываться или затухать при backpropagation? Какие вы знаете способы чтобы это исправить? Что такое gradient clipping?  
3. Что такое dropout, как он влияет на обучение сети?    
4. Объясните механизм batch normalization. Как он влияет на сходимость оптимизации.   
5. Inductive bias. Примеры.  
6. Какие недостатки batchnorm для работы с последовательностями переменной длины? Какие вы знаете альтернативы его использованию?   
7. Как устроен autograd в библиотеке PyTorch?    
8. Адаптивные оптимизаторы. Какие основные? Какие есть особенности в использование с weight decay?
9. Архитектура ResNet. Как shortcut-соединения влияют на градиенты?    
10. Что такое transfer learning в CNN: какие слои принято «замораживать» и почему?
11. Что такое LoRA? В чем основная идея и для чего используется?
12. Опишите различия между задачами object detection и semantic segmentation. Основные метрики.    
13. Что такое Receptive field? Как можно увеличить Receptive field?  
15. LSTM, RNN vs Seq2Seq+Attention.     
16. Что такое self-attention? Какая связь с рекуррентностью в Transformer?  
17. KV-cache: основная идея, зачем используют?  
18. Как работает позиционное кодирование в архитектуре Transformer и какие есть его разновидности?    
19. Pre-training / fine-tuning BERT.  
20. Что такое лог-мел спектрограмма. Почему она используется вместо вейвформы в ASR?    
21. Какие виды аудио-аугментаций вы знаете?    
22. Объясните принцип обучения GAN. Опишите проблему mode collapse.    
23. Как Wasserstein-GAN решает проблемы классического GAN? Что такое gradient penalty?    
24. Что такое NeRF? Какую задачу он решает?   
25. В чём архитектурные преимущества ViT и как они проявляются при работе с high-res изображениями?   
26. Какие трюки позволяют снизить квадратичную сложность self-attention?  
27. Как работает контрастивное обучение в CLIP? В чем мультимодальность?    
28. GNN. Какие задачи решают GNN?
